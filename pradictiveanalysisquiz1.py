# -*- coding: utf-8 -*-
"""pradictiveanalysisquiz1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/13VW72Vwr9YAFfZXTTL3ZGPjKXi6G8Smn
"""

import pandas as pd
df = pd.read_csv('/content/sample_data/DSAI-LVA-DATASET for Quiz.csv')

total_rows = len(df)
split_ratio = 0.7
split_index = int(total_rows * split_ratio)

train_df = df.iloc[:split_index, :]
test_df = df.iloc[split_index:, :]

train_df.to_csv('train_data.csv', index=False)
test_df.to_csv('test_data.csv', index=False)

df.tail()

df1 = pd.read_csv('train_data.csv')
df1.tail()

df2 = pd.read_csv('test_data.csv')
df2.tail()



import pandas as pd
from sklearn.preprocessing import LabelEncoder
from sklearn.ensemble import RandomForestClassifier
from xgboost import XGBClassifier
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix

# Handle missing values if any
df1.dropna(inplace=True)

# Encode categorical variables
label_encoder = LabelEncoder()
df1['ParentEducation'] = label_encoder.fit_transform(df1['ParentEducation'])
df1['Pass'] = label_encoder.fit_transform(df1['Pass'])

# Separate data into training and test sets
train_data = df1.sample(frac=0.7, random_state=42)
test_data = df1.drop(train_data.index)

# Separate features and target variable
X_train = train_data[['StudyTime', 'PreviousTestScore', 'ParentEducation']]
y_train = train_data['Pass']
X_test = test_data[['StudyTime', 'PreviousTestScore', 'ParentEducation']]
y_test = test_data['Pass']

# Initialize and train models (Random Forest and XGBoost)
rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)
xgb_classifier = XGBClassifier()

rf_classifier.fit(X_train, y_train)
xgb_classifier.fit(X_train, y_train)

# Make predictions
rf_pred = rf_classifier.predict(X_test)
xgb_pred = xgb_classifier.predict(X_test)

# Evaluate models
rf_accuracy = accuracy_score(y_test, rf_pred)
xgb_accuracy = accuracy_score(y_test, xgb_pred)

rf_report = classification_report(y_test, rf_pred)
xgb_report = classification_report(y_test, xgb_pred)

rf_conf_matrix = confusion_matrix(y_test, rf_pred)
xgb_conf_matrix = confusion_matrix(y_test, xgb_pred)

print(f"Random Forest Accuracy: {rf_accuracy}")
print(f"Random Forest Classification Report:\n{rf_report}")
print(f"Random Forest Confusion Matrix:\n{rf_conf_matrix}\n")
print(f"XGBoost Accuracy: {xgb_accuracy}")
print(f"XGBoost Classification Report:\n{xgb_report}")
print(f"XGBoost Confusion Matrix:\n{xgb_conf_matrix}")


# Make predictions
rf_pred = rf_classifier.predict(X_test)
xgb_pred = xgb_classifier.predict(X_test)

# Add predictions to DataFrame
test_data['RF_Prediction'] = rf_pred
test_data['XGB_Prediction'] = xgb_pred

# Define categories based on predictions
def categorize_pass(row):
    if row['RF_Prediction'] == 1 and row['XGB_Prediction'] == 1:
        return 'Pass with High Score'
    elif row['RF_Prediction'] == 1 and row['XGB_Prediction'] == 0:
        return 'Pass with Low Score'
    else:
        return 'Fail'

# Apply categorization function
test_data['Pass_Category'] = test_data.apply(categorize_pass, axis=1)

# Save updated data file with categories
test_data.to_csv('student_dataset_with_categories(test).csv', index=False)

df3 = pd.read_csv('/content/student_dataset_with_categories.csv')
df3.head()



# Handle missing values if any
df2.dropna(inplace=True)

# Encode categorical variables
label_encoder = LabelEncoder()
df2['ParentEducation'] = label_encoder.fit_transform(df2['ParentEducation'])
df2['Pass'] = label_encoder.fit_transform(df2['Pass'])

# Separate data into training and test sets
train_data = df2.sample(frac=0.7, random_state=42)
test_data = df2.drop(train_data.index)

# Separate features and target variable
X_train = train_data[['StudyTime', 'PreviousTestScore', 'ParentEducation']]
y_train = train_data['Pass']
X_test = test_data[['StudyTime', 'PreviousTestScore', 'ParentEducation']]
y_test = test_data['Pass']

# Initialize and train models (Random Forest and XGBoost)
rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)
xgb_classifier = XGBClassifier()

rf_classifier.fit(X_train, y_train)
xgb_classifier.fit(X_train, y_train)

# Make predictions
rf_pred = rf_classifier.predict(X_test)
xgb_pred = xgb_classifier.predict(X_test)

# Evaluate models
rf_accuracy = accuracy_score(y_test, rf_pred)
xgb_accuracy = accuracy_score(y_test, xgb_pred)

rf_report = classification_report(y_test, rf_pred)
xgb_report = classification_report(y_test, xgb_pred)

rf_conf_matrix = confusion_matrix(y_test, rf_pred)
xgb_conf_matrix = confusion_matrix(y_test, xgb_pred)

print(f"Random Forest Accuracy: {rf_accuracy}")
print(f"Random Forest Classification Report:\n{rf_report}")
print(f"Random Forest Confusion Matrix:\n{rf_conf_matrix}\n")
print(f"XGBoost Accuracy: {xgb_accuracy}")
print(f"XGBoost Classification Report:\n{xgb_report}")
print(f"XGBoost Confusion Matrix:\n{xgb_conf_matrix}")

# Make predictions
rf_pred = rf_classifier.predict(X_test)
xgb_pred = xgb_classifier.predict(X_test)

# Add predictions to DataFrame
test_data['RF_Prediction'] = rf_pred
test_data['XGB_Prediction'] = xgb_pred

# Define categories based on predictions
def categorize_pass(row):
    if row['RF_Prediction'] == 1 and row['XGB_Prediction'] == 1:
        return 'Pass with High Score'
    elif row['RF_Prediction'] == 1 and row['XGB_Prediction'] == 0:
        return 'Pass with Low Score'
    else:
        return 'Fail'

# Apply categorization function
test_data['Pass_Category'] = test_data.apply(categorize_pass, axis=1)

# Save updated data file with categories
test_data.to_csv('student_dataset_with_categories(train).csv', index=False)

df4 = pd.read_csv('/content/student_dataset_with_categories(train).csv')
df4.head()

